{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a56feda9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark = org.apache.spark.sql.SparkSession@104b1be6\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession@104b1be6"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.hadoop.fs.{FileSystem, Path}\n",
    "\n",
    "// Initialize SparkSession\n",
    "val spark = SparkSession.builder()\n",
    "    .appName(\"Partitioning Ratings Data by Year\")\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e8dcd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      "\n",
      "+------+-------+------+-------------------+\n",
      "|userId|movieId|rating|          timestamp|\n",
      "+------+-------+------+-------------------+\n",
      "|     1|      2|   3.5|2005-04-02 23:53:47|\n",
      "|     1|     29|   3.5|2005-04-02 23:31:16|\n",
      "|     1|     32|   3.5|2005-04-02 23:33:39|\n",
      "|     1|     47|   3.5|2005-04-02 23:32:07|\n",
      "|     1|     50|   3.5|2005-04-02 23:29:40|\n",
      "|     1|    112|   3.5|2004-09-10 03:09:00|\n",
      "|     1|    151|   4.0|2004-09-10 03:08:54|\n",
      "|     1|    223|   4.0|2005-04-02 23:46:13|\n",
      "|     1|    253|   4.0|2005-04-02 23:35:40|\n",
      "|     1|    260|   4.0|2005-04-02 23:33:46|\n",
      "+------+-------+------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ratingsPath = gs://task-dataset-bucket/Day_16_17/rating.csv\n",
       "ratingsDF = [userId: int, movieId: int ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[userId: int, movieId: int ... 2 more fields]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ratingsPath = \"gs://task-dataset-bucket/Day_16_17/rating.csv\"\n",
    "val ratingsDF = spark.read\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .csv(ratingsPath)\n",
    "\n",
    "// Inspect Schema\n",
    "ratingsDF.printSchema()\n",
    "ratingsDF.show(10) // Display first 10 rows for verification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "285c3b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+-------------------+----+\n",
      "|userId|movieId|rating|          timestamp|year|\n",
      "+------+-------+------+-------------------+----+\n",
      "|     1|      2|   3.5|2005-04-02 23:53:47|2005|\n",
      "|     1|     29|   3.5|2005-04-02 23:31:16|2005|\n",
      "|     1|     32|   3.5|2005-04-02 23:33:39|2005|\n",
      "|     1|     47|   3.5|2005-04-02 23:32:07|2005|\n",
      "|     1|     50|   3.5|2005-04-02 23:29:40|2005|\n",
      "|     1|    112|   3.5|2004-09-10 03:09:00|2004|\n",
      "|     1|    151|   4.0|2004-09-10 03:08:54|2004|\n",
      "|     1|    223|   4.0|2005-04-02 23:46:13|2005|\n",
      "|     1|    253|   4.0|2005-04-02 23:35:40|2005|\n",
      "|     1|    260|   4.0|2005-04-02 23:33:46|2005|\n",
      "+------+-------+------+-------------------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "enhancedRatingsDF = [userId: int, movieId: int ... 3 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[userId: int, movieId: int ... 3 more fields]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val enhancedRatingsDF = ratingsDF.withColumn(\"year\", year(col(\"timestamp\")))\n",
    "\n",
    "// Show updated DataFrame\n",
    "enhancedRatingsDF.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "053aac09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in limited dataset: 100000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "limitedRatingsDF = [userId: int, movieId: int ... 3 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[userId: int, movieId: int ... 3 more fields]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val limitedRatingsDF = enhancedRatingsDF.limit(100000)\n",
    "\n",
    "// Verify record count\n",
    "println(s\"Number of records in limited dataset: ${limitedRatingsDF.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c51ef7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to: hdfs:///user/day_16_17/partitioned_ratings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "partitionedOutputPath = hdfs:///user/day_16_17/partitioned_ratings\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "hdfs:///user/day_16_17/partitioned_ratings"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val partitionedOutputPath = \"hdfs:///user/day_16_17/partitioned_ratings\"\n",
    "\n",
    "limitedRatingsDF.coalesce(1)\n",
    "    .write\n",
    "    .partitionBy(\"year\")\n",
    "    .format(\"parquet\")\n",
    "    .mode(\"overwrite\")\n",
    "    .save(partitionedOutputPath)\n",
    "\n",
    "println(s\"Data saved to: $partitionedOutputPath\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45d05c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|year|\n",
      "+----+\n",
      "|1996|\n",
      "+----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "partitionPath = hdfs:///user/day_16_17/partitioned_ratings/year=1996\n",
       "partitionedData = [userId: int, movieId: int ... 3 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[userId: int, movieId: int ... 3 more fields]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val partitionPath = \"hdfs:///user/day_16_17/partitioned_ratings/year=1996\"\n",
    "\n",
    "val partitionedData = spark.read\n",
    "    .option(\"basePath\", partitionedOutputPath)\n",
    "    .parquet(partitionPath)\n",
    "\n",
    "// Show distinct years from the partitioned dataset\n",
    "partitionedData.select(\"year\").distinct().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84edd5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.12.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}