{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddc8a9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark = org.apache.spark.sql.SparkSession@3b8a02b3\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession@3b8a02b3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.Row\n",
    "import org.apache.spark.rdd.RDD\n",
    "import org.apache.hadoop.fs.{FileSystem, Path}\n",
    "import scala.util.matching.Regex\n",
    "import org.apache.spark.sql.types._\n",
    "\n",
    "// Initialize SparkSession\n",
    "val spark = SparkSession.builder()\n",
    "    .appName(\"CaseStudy4 - Duplicate Record Removal Pipeline\")\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-avro_2.12:3.4.0\")\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8d1ab60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
      "|      5|Father of the Bri...|              Comedy|\n",
      "|      6|         Heat (1995)|Action|Crime|Thri...|\n",
      "|      7|      Sabrina (1995)|      Comedy|Romance|\n",
      "|      8| Tom and Huck (1995)|  Adventure|Children|\n",
      "|      9| Sudden Death (1995)|              Action|\n",
      "|     10|    GoldenEye (1995)|Action|Adventure|...|\n",
      "|     11|American Presiden...|Comedy|Drama|Romance|\n",
      "|     12|Dracula: Dead and...|       Comedy|Horror|\n",
      "|     13|        Balto (1995)|Adventure|Animati...|\n",
      "|     14|        Nixon (1995)|               Drama|\n",
      "|     15|Cutthroat Island ...|Action|Adventure|...|\n",
      "|     16|       Casino (1995)|         Crime|Drama|\n",
      "|     17|Sense and Sensibi...|       Drama|Romance|\n",
      "|     18|   Four Rooms (1995)|              Comedy|\n",
      "|     19|Ace Ventura: When...|              Comedy|\n",
      "|     20|  Money Train (1995)|Action|Comedy|Cri...|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "moviesDataPath = gs://task-dataset-bucket/Day_16_17/movie.csv\n",
       "moviesDF = [movieId: int, title: string ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[movieId: int, title: string ... 1 more field]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val moviesDataPath = \"gs://task-dataset-bucket/Day_16_17/movie.csv\"\n",
    "val moviesDF = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(moviesDataPath)\n",
    "\n",
    "// Show sample data\n",
    "moviesDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5df4fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Count: 27278, Deduplicated Count: 27278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "initialCount = 27278\n",
       "deduplicatedCount = 27278\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "27278"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val initialCount = moviesDF.count()\n",
    "\n",
    "// Drop duplicates and count records\n",
    "val deduplicatedCount = moviesDF.dropDuplicates(\"movieId\", \"title\").count()\n",
    "\n",
    "println(s\"Initial Count: $initialCount, Deduplicated Count: $deduplicatedCount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dd57ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies in 1971: 205, Unioned Count: 27483\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "moviesIn1971 = [movieId: int, title: string ... 1 more field]\n",
       "moviesIn1971Count = 205\n",
       "unionDF = [movieId: int, title: string ... 1 more field]\n",
       "unionDFCount = 27483\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "27483"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val moviesIn1971 = moviesDF.filter(col(\"title\").contains(\"(1971)\"))\n",
    "val moviesIn1971Count = moviesIn1971.count()\n",
    "\n",
    "// Union original DataFrame with the 1971 movies to create duplicates\n",
    "val unionDF = moviesDF.union(moviesIn1971)\n",
    "val unionDFCount = unionDF.count()\n",
    "\n",
    "println(s\"Movies in 1971: $moviesIn1971Count, Unioned Count: $unionDFCount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "052550d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hdfsPath = hdfs:///user/day_16_17/duplicate_movies\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "hdfs:///user/day_16_17/duplicate_movies"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val hdfsPath = \"hdfs:///user/day_16_17/duplicate_movies\"\n",
    "\n",
    "// Write unioned data to HDFS\n",
    "unionDF.write.mode(\"overwrite\").csv(hdfsPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24415c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Count: 27483\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "moviesSchema = StructType(StructField(movieId,IntegerType,true),StructField(title,StringType,true),StructField(genres,StringType,true))\n",
       "moviesUpdatedDF = [movieId: int, title: string ... 1 more field]\n",
       "updatedCount = 27483\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "27483"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val moviesSchema = StructType(Array(\n",
    "    StructField(\"movieId\", IntegerType, nullable = true),\n",
    "    StructField(\"title\", StringType, nullable = true),\n",
    "    StructField(\"genres\", StringType, nullable = true)\n",
    "))\n",
    "\n",
    "val moviesUpdatedDF = spark.read.schema(moviesSchema).option(\"header\", \"false\").csv(hdfsPath)\n",
    "\n",
    "// Count records in updated DataFrame\n",
    "val updatedCount = moviesUpdatedDF.count()\n",
    "\n",
    "println(s\"Updated Count: $updatedCount\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20ce8789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Count: 27278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "filteredRDD = MapPartitionsRDD[65] at map at <console>:40\n",
       "filteredCount = 27278\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "27278"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val filteredRDD = moviesUpdatedDF.rdd.map { row =>\n",
    "    val movieId = row.getAs[Int](\"movieId\")\n",
    "    val title = row.getAs[String](\"title\")\n",
    "    ((movieId, title), row)\n",
    "}.reduceByKey((row1, _) => row1)\n",
    " .map { case (_, row) => row }\n",
    "\n",
    "// Count records in filtered RDD\n",
    "val filteredCount = filteredRDD.count()\n",
    "println(s\"Filtered Count: $filteredCount\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41d9b323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gsPath = gs://task-dataset-bucket/Day_16_17/cleaned_movies\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "gs://task-dataset-bucket/Day_16_17/cleaned_movies"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Save filtered data to Avro format\n",
    "val gsPath = \"gs://task-dataset-bucket/Day_16_17/cleaned_movies\"\n",
    "\n",
    "filteredRDD.map { row =>\n",
    "    val movieId = row.getAs[Int](\"movieId\")\n",
    "    val title = row.getAs[String](\"title\")\n",
    "    val genres = row.getAs[String](\"genres\")\n",
    "    (movieId, title, genres)\n",
    "}.toDF(\"movieId\", \"title\", \"genres\")\n",
    ".write\n",
    ".format(\"avro\")\n",
    ".mode(\"overwrite\")\n",
    ".save(gsPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "743c574c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|  82108|Against the Curre...|               Drama|\n",
      "|  94133|  Hammer, The (2010)|               Drama|\n",
      "|  91284|Lonely Passion of...|       Drama|Romance|\n",
      "|  96717|Pearls of the Cro...|              Comedy|\n",
      "|  69042|Flash Gordon's Tr...|       Action|Sci-Fi|\n",
      "|   3530|Smoking/No Smokin...|              Comedy|\n",
      "|  73449| V.I.P.s, The (1963)|               Drama|\n",
      "|  27783|Lost Embrace (Abr...|        Comedy|Drama|\n",
      "|  32369|Panic in the Stre...|Crime|Drama|Film-...|\n",
      "|   4077|With a Friend Lik...|      Drama|Thriller|\n",
      "| 127248|  The Auction (2013)|               Drama|\n",
      "|   1584|      Contact (1997)|        Drama|Sci-Fi|\n",
      "|  89896|Turin Horse, The ...|               Drama|\n",
      "|  73392|     Collapse (2009)|         Documentary|\n",
      "|  85378|Mother Carey's Ch...|       Drama|Romance|\n",
      "|   5131|How to Kill Your ...|        Comedy|Drama|\n",
      "|  75421|Girl of Finland (...|               Drama|\n",
      "|   7893|Return of the Str...|  Action|Crime|Drama|\n",
      "| 122478|Peter and Vandy (...|Comedy|Drama|Romance|\n",
      "| 127232|  The Referee (2013)|              Comedy|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Final Record Count: 27278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "validationDF = [movieId: int, title: string ... 1 more field]\n",
       "finalCount = 27278\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "27278"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val validationDF = spark.read.format(\"avro\").load(gsPath)\n",
    "\n",
    "// Show sample data and count\n",
    "validationDF.show()\n",
    "val finalCount = validationDF.count()\n",
    "\n",
    "println(s\"Final Record Count: $finalCount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ddbca90",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72989818",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.12.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}